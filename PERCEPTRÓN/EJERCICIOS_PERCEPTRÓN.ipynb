{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5rDA6JJzCNAoEi6NaUljk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beatoy/INTELIGENCIA-ARTIFICIAL/blob/main/PERCEPTR%C3%93N/EJERCICIOS_PERCEPTR%C3%93N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2DaoS11V9xc",
        "outputId": "585ad815-109c-4200-d4cb-bb695d0fc120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Optimized Weights are [0.99 0.49], and bias is 0.97\n",
            "Epoch 1, Optimized Weights are [0.98 0.48], and bias is 0.94\n",
            "Epoch 2, Optimized Weights are [0.97 0.47], and bias is 0.9099999999999999\n",
            "Epoch 3, Optimized Weights are [0.96 0.46], and bias is 0.8799999999999999\n",
            "Epoch 4, Optimized Weights are [0.95 0.45], and bias is 0.8499999999999999\n",
            "Epoch 5, Optimized Weights are [0.94 0.44], and bias is 0.8199999999999998\n",
            "Epoch 6, Optimized Weights are [0.93 0.43], and bias is 0.7899999999999998\n",
            "Epoch 7, Optimized Weights are [0.92 0.42], and bias is 0.7599999999999998\n",
            "Epoch 8, Optimized Weights are [0.91 0.41], and bias is 0.7299999999999998\n",
            "Epoch 9, Optimized Weights are [0.9 0.4], and bias is 0.6999999999999997\n",
            "Epoch 10, Optimized Weights are [0.89 0.39], and bias is 0.6699999999999997\n",
            "Epoch 11, Optimized Weights are [0.88 0.38], and bias is 0.6399999999999997\n",
            "Epoch 12, Optimized Weights are [0.87 0.37], and bias is 0.6099999999999997\n",
            "Epoch 13, Optimized Weights are [0.86 0.36], and bias is 0.5799999999999996\n",
            "Epoch 14, Optimized Weights are [0.85 0.35], and bias is 0.5499999999999996\n",
            "Epoch 15, Optimized Weights are [0.84 0.34], and bias is 0.5199999999999996\n",
            "Epoch 16, Optimized Weights are [0.83 0.33], and bias is 0.48999999999999955\n",
            "Epoch 17, Optimized Weights are [0.82 0.32], and bias is 0.4599999999999995\n",
            "Epoch 18, Optimized Weights are [0.81 0.31], and bias is 0.4299999999999995\n",
            "Epoch 19, Optimized Weights are [0.8 0.3], and bias is 0.39999999999999947\n",
            "Epoch 20, Optimized Weights are [0.79 0.29], and bias is 0.36999999999999944\n",
            "Epoch 21, Optimized Weights are [0.78 0.28], and bias is 0.3399999999999994\n",
            "Epoch 22, Optimized Weights are [0.77 0.27], and bias is 0.3099999999999994\n",
            "Epoch 23, Optimized Weights are [0.76 0.26], and bias is 0.27999999999999936\n",
            "Epoch 24, Optimized Weights are [0.75 0.25], and bias is 0.24999999999999933\n",
            "Epoch 25, Optimized Weights are [0.74 0.24], and bias is 0.2199999999999993\n",
            "Epoch 26, Optimized Weights are [0.73 0.23], and bias is 0.18999999999999928\n",
            "Epoch 27, Optimized Weights are [0.72 0.22], and bias is 0.15999999999999925\n",
            "Epoch 28, Optimized Weights are [0.71 0.21], and bias is 0.12999999999999923\n",
            "Epoch 29, Optimized Weights are [0.7 0.2], and bias is 0.09999999999999924\n",
            "Epoch 30, Optimized Weights are [0.69 0.19], and bias is 0.06999999999999926\n",
            "Epoch 31, Optimized Weights are [0.68 0.18], and bias is 0.03999999999999925\n",
            "Epoch 32, Optimized Weights are [0.67 0.17], and bias is 0.009999999999999247\n",
            "Epoch 33, Optimized Weights are [0.66 0.16], and bias is -0.020000000000000753\n",
            "Epoch 34, Optimized Weights are [0.65 0.15], and bias is -0.04000000000000076\n",
            "Epoch 35, Optimized Weights are [0.64 0.14], and bias is -0.06000000000000076\n",
            "Epoch 36, Optimized Weights are [0.63 0.13], and bias is -0.08000000000000075\n",
            "Epoch 37, Optimized Weights are [0.62 0.12], and bias is -0.10000000000000074\n",
            "Epoch 38, Optimized Weights are [0.61 0.11], and bias is -0.12000000000000073\n",
            "Epoch 39, Optimized Weights are [0.6  0.11], and bias is -0.13000000000000073\n",
            "Epoch 40, Optimized Weights are [0.59 0.11], and bias is -0.14000000000000073\n",
            "Epoch 41, Optimized Weights are [0.58 0.11], and bias is -0.15000000000000074\n",
            "Epoch 42, Optimized Weights are [0.57 0.11], and bias is -0.16000000000000075\n",
            "Epoch 43, Optimized Weights are [0.56 0.11], and bias is -0.17000000000000076\n",
            "Epoch 44, Optimized Weights are [0.55 0.11], and bias is -0.18000000000000077\n",
            "Epoch 45, Optimized Weights are [0.54 0.11], and bias is -0.19000000000000078\n",
            "Epoch 46, Optimized Weights are [0.53 0.11], and bias is -0.2000000000000008\n",
            "Epoch 47, Optimized Weights are [0.52 0.11], and bias is -0.2100000000000008\n",
            "Epoch 48, Optimized Weights are [0.51 0.11], and bias is -0.2200000000000008\n",
            "Epoch 49, Optimized Weights are [0.5  0.11], and bias is -0.23000000000000081\n",
            "Epoch 50, Optimized Weights are [0.49 0.11], and bias is -0.24000000000000082\n",
            "Epoch 51, Optimized Weights are [0.48 0.11], and bias is -0.25000000000000083\n",
            "Epoch 52, Optimized Weights are [0.47 0.11], and bias is -0.26000000000000084\n",
            "Epoch 53, Optimized Weights are [0.46 0.11], and bias is -0.27000000000000085\n",
            "Epoch 54, Optimized Weights are [0.45 0.11], and bias is -0.28000000000000086\n",
            "Epoch 55, Optimized Weights are [0.44 0.11], and bias is -0.29000000000000087\n",
            "Epoch 56, Optimized Weights are [0.43 0.11], and bias is -0.3000000000000009\n",
            "Epoch 57, Optimized Weights are [0.42 0.11], and bias is -0.3100000000000009\n",
            "Epoch 58, Optimized Weights are [0.41 0.11], and bias is -0.3200000000000009\n",
            "Epoch 59, Optimized Weights are [0.4  0.11], and bias is -0.3300000000000009\n",
            "Epoch 60, Optimized Weights are [0.39 0.11], and bias is -0.3400000000000009\n",
            "Epoch 61, Optimized Weights are [0.38 0.11], and bias is -0.3500000000000009\n",
            "Epoch 62, Optimized Weights are [0.37 0.11], and bias is -0.36000000000000093\n",
            "Epoch 63, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 64, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 65, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 66, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 67, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 68, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 69, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 70, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 71, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 72, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 73, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 74, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 75, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 76, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 77, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 78, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 79, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 80, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 81, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 82, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 83, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 84, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 85, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 86, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 87, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 88, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 89, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 90, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 91, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 92, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 93, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 94, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 95, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 96, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 97, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 98, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Epoch 99, Optimized Weights are [0.36 0.11], and bias is -0.37000000000000094\n",
            "Optimized Weights are [0.36 0.11] and bias is -0.37000000000000094\n",
            "Input: [0 0], Predictions: 0\n",
            "Input: [0 1], Predictions: 0\n",
            "Input: [1 0], Predictions: 0\n",
            "Input: [1 1], Predictions: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Entradas para el perceptron\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "# Salidas\n",
        "Y = np.array([0, 0, 0, 1])\n",
        "# Pesos para las entradas\n",
        "weights = np.array([1.0, 0.5])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.01\n",
        "# Epocas\n",
        "epochs = 100\n",
        "# Sesgo\n",
        "bias =  1.0\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            print(f\"Epoch {epoch}, Optimized Weights are {self.weights}, and bias is {self.bias}\")\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activacion escalon\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        # Mensaje input y su predicción\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predictions: {self.activation_function(sum_[i])}\")\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])\n",
        "\n",
        "# Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "# Usar el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Entradas para el perceptrón (todas las combinaciones de A y B)\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "# Salidas esperadas (operación OR)\n",
        "Y = np.array([0, 1, 1, 1])\n",
        "# Pesos iniciales\n",
        "weights = np.array([0.5, 0.5])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.1\n",
        "# Número de épocas (vueltas de entrenamiento)\n",
        "epochs = 20\n",
        "# Sesgo (bias)\n",
        "bias = -0.5\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "        Entrena el perceptrón ajustando pesos y sesgo.\n",
        "        \"\"\"\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            # Imprime los resultados de cada época\n",
        "            print(f\"Época {epoch}: Pesos = {self.weights}, Bias = {self.bias}\")\n",
        "        print(f\"\\nPesos finales: {self.weights}, Bias final: {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "        Función de activación tipo escalón (step function).\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "        Calcula la salida del perceptrón ya entrenado.\n",
        "        \"\"\"\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Entrada: {X[i]}, Salida predicha: {self.activation_function(s)}\")\n",
        "        return np.array([self.activation_function(s) for s in sum_])\n",
        "\n",
        "# Crear una instancia del perceptrón para OR\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "\n",
        "# Realizar las predicciones finales\n",
        "predictions = p.prediction(X)\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(\"\\nEntradas:\\n\", X)\n",
        "print(\"Salidas esperadas (OR):\", Y)\n",
        "print(\"Salidas predichas:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxmzLBuDWqeJ",
        "outputId": "b6bcf0ea-d45b-497b-8381-a682b31be1e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 1: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 2: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 3: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 4: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 5: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 6: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 7: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 8: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 9: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 10: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 11: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 12: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 13: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 14: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 15: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 16: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 17: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 18: Pesos = [0.5 0.5], Bias = -0.5\n",
            "Época 19: Pesos = [0.5 0.5], Bias = -0.5\n",
            "\n",
            "Pesos finales: [0.5 0.5], Bias final: -0.5\n",
            "Entrada: [0 0], Salida predicha: 0\n",
            "Entrada: [0 1], Salida predicha: 1\n",
            "Entrada: [1 0], Salida predicha: 1\n",
            "Entrada: [1 1], Salida predicha: 1\n",
            "\n",
            "Entradas:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "Salidas esperadas (OR): [0 1 1 1]\n",
            "Salidas predichas: [0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Entradas para el perceptron\n",
        "X = np.array([[1],\n",
        "              [2],\n",
        "              [3],\n",
        "              [4]])\n",
        "# Salidas\n",
        "Y = np.array([2, 4, 6, 8])\n",
        "# Pesos para las entradas\n",
        "weights = np.array([0.5])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.1\n",
        "# Epocas\n",
        "epochs = 100\n",
        "# Sesgo\n",
        "bias =  0.5\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            print(f\"Epoch {epoch}, Optimized Weights are {self.weights}, and bias is {self.bias}\")\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activacion ReLU\n",
        "        \"\"\"\n",
        "        return np.maximum(0, activation)\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        # Mensaje input y su predicción\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predictions: {self.activation_function(sum_[i])}\")\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])\n",
        "\n",
        "# Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "# Usar el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCgP5cszWtja",
        "outputId": "5b61b7fd-3911-4328-a08f-52566a28b5f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Optimized Weights are [1.7948], and bias is 1.0602\n",
            "Epoch 1, Optimized Weights are [1.8094718], and bias is 0.9843957\n",
            "Epoch 2, Optimized Weights are [1.82309457], and bias is 0.9140114074499999\n",
            "Epoch 3, Optimized Weights are [1.8357433], and bias is 0.8486595918173249\n",
            "Epoch 4, Optimized Weights are [1.84748766], and bias is 0.7879804310023861\n",
            "Epoch 5, Optimized Weights are [1.85839229], and bias is 0.7316398301857157\n",
            "Epoch 6, Optimized Weights are [1.86851724], and bias is 0.6793275823274367\n",
            "Epoch 7, Optimized Weights are [1.87791826], and bias is 0.630755660191025\n",
            "Epoch 8, Optimized Weights are [1.8866471], and bias is 0.5856566304873667\n",
            "Epoch 9, Optimized Weights are [1.89475184], and bias is 0.5437821814075201\n",
            "Epoch 10, Optimized Weights are [1.90227708], and bias is 0.5049017554368825\n",
            "Epoch 11, Optimized Weights are [1.90926427], and bias is 0.4688012799231454\n",
            "Epoch 12, Optimized Weights are [1.91575187], and bias is 0.4352819884086404\n",
            "Epoch 13, Optimized Weights are [1.92177561], and bias is 0.4041593262374226\n",
            "Epoch 14, Optimized Weights are [1.92736866], and bias is 0.3752619344114469\n",
            "Epoch 15, Optimized Weights are [1.9325618], and bias is 0.3484307061010285\n",
            "Epoch 16, Optimized Weights are [1.93738363], and bias is 0.3235179106148049\n",
            "Epoch 17, Optimized Weights are [1.9418607], and bias is 0.3003863800058463\n",
            "Epoch 18, Optimized Weights are [1.94601766], and bias is 0.2789087538354283\n",
            "Epoch 19, Optimized Weights are [1.9498774], and bias is 0.2589667779361951\n",
            "Epoch 20, Optimized Weights are [1.95346116], and bias is 0.24045065331375723\n",
            "Epoch 21, Optimized Weights are [1.95678869], and bias is 0.22325843160182351\n",
            "Epoch 22, Optimized Weights are [1.9598783], and bias is 0.20729545374229322\n",
            "Epoch 23, Optimized Weights are [1.962747], and bias is 0.1924738287997191\n",
            "Epoch 24, Optimized Weights are [1.96541059], and bias is 0.17871195004053916\n",
            "Epoch 25, Optimized Weights are [1.96788373], and bias is 0.16593404561264077\n",
            "Epoch 26, Optimized Weights are [1.97018005], and bias is 0.15406976135133696\n",
            "Epoch 27, Optimized Weights are [1.97231217], and bias is 0.14305377341471626\n",
            "Epoch 28, Optimized Weights are [1.97429185], and bias is 0.13282542861556412\n",
            "Epoch 29, Optimized Weights are [1.97612999], and bias is 0.12332841046955126\n",
            "Epoch 30, Optimized Weights are [1.97783669], and bias is 0.11451042912097835\n",
            "Epoch 31, Optimized Weights are [1.97942137], and bias is 0.10632293343882823\n",
            "Epoch 32, Optimized Weights are [1.98089274], and bias is 0.09872084369795207\n",
            "Epoch 33, Optimized Weights are [1.98225891], and bias is 0.09166230337354858\n",
            "Epoch 34, Optimized Weights are [1.9835274], and bias is 0.08510844868233984\n",
            "Epoch 35, Optimized Weights are [1.98470519], and bias is 0.07902319460155247\n",
            "Epoch 36, Optimized Weights are [1.98579877], and bias is 0.07337303618754157\n",
            "Epoch 37, Optimized Weights are [1.98681416], and bias is 0.06812686410013225\n",
            "Epoch 38, Optimized Weights are [1.98775694], and bias is 0.06325579331697284\n",
            "Epoch 39, Optimized Weights are [1.98863232], and bias is 0.05873300409480917\n",
            "Epoch 40, Optimized Weights are [1.98944511], and bias is 0.054533594302030246\n",
            "Epoch 41, Optimized Weights are [1.99019979], and bias is 0.05063444230943498\n",
            "Epoch 42, Optimized Weights are [1.9909005], and bias is 0.04701407968431038\n",
            "Epoch 43, Optimized Weights are [1.99155111], and bias is 0.043652572986882236\n",
            "Epoch 44, Optimized Weights are [1.99215521], and bias is 0.040531414018320125\n",
            "Epoch 45, Optimized Weights are [1.99271611], and bias is 0.03763341791601041\n",
            "Epoch 46, Optimized Weights are [1.99323691], and bias is 0.034942628535015625\n",
            "Epoch 47, Optimized Weights are [1.99372047], and bias is 0.032444230594761876\n",
            "Epoch 48, Optimized Weights are [1.99416946], and bias is 0.030124468107236443\n",
            "Epoch 49, Optimized Weights are [1.99458634], and bias is 0.027970568637569002\n",
            "Epoch 50, Optimized Weights are [1.99497342], and bias is 0.025970672979982734\n",
            "Epoch 51, Optimized Weights are [1.99533282], and bias is 0.0241137698619141\n",
            "Epoch 52, Optimized Weights are [1.99566652], and bias is 0.022389635316787136\n",
            "Epoch 53, Optimized Weights are [1.99597637], and bias is 0.020788776391636843\n",
            "Epoch 54, Optimized Weights are [1.99626406], and bias is 0.019302378879634943\n",
            "Epoch 55, Optimized Weights are [1.99653118], and bias is 0.017922258789740936\n",
            "Epoch 56, Optimized Weights are [1.9967792], and bias is 0.016640817286274572\n",
            "Epoch 57, Optimized Weights are [1.99700948], and bias is 0.015450998850305911\n",
            "Epoch 58, Optimized Weights are [1.99722331], and bias is 0.014346252432508838\n",
            "Epoch 59, Optimized Weights are [1.99742184], and bias is 0.013320495383584478\n",
            "Epoch 60, Optimized Weights are [1.99760618], and bias is 0.012368079963658267\n",
            "Epoch 61, Optimized Weights are [1.99777734], and bias is 0.011483762246256572\n",
            "Epoch 62, Optimized Weights are [1.99793626], and bias is 0.010662673245649283\n",
            "Epoch 63, Optimized Weights are [1.99808381], and bias is 0.0099002921085854\n",
            "Epoch 64, Optimized Weights are [1.99822082], and bias is 0.009192421222821661\n",
            "Epoch 65, Optimized Weights are [1.99834803], and bias is 0.008535163105389834\n",
            "Epoch 66, Optimized Weights are [1.99846615], and bias is 0.007924898943354432\n",
            "Epoch 67, Optimized Weights are [1.99857582], and bias is 0.007358268668904669\n",
            "Epoch 68, Optimized Weights are [1.99867765], and bias is 0.006832152459078036\n",
            "Epoch 69, Optimized Weights are [1.9987722], and bias is 0.006343653558253917\n",
            "Epoch 70, Optimized Weights are [1.99885998], and bias is 0.005890082328838734\n",
            "Epoch 71, Optimized Weights are [1.9989415], and bias is 0.005468941442326805\n",
            "Epoch 72, Optimized Weights are [1.99901718], and bias is 0.0050779121292004485\n",
            "Epoch 73, Optimized Weights are [1.99908745], and bias is 0.004714841411962536\n",
            "Epoch 74, Optimized Weights are [1.9991527], and bias is 0.00437773025100722\n",
            "Epoch 75, Optimized Weights are [1.99921328], and bias is 0.004064722538060309\n",
            "Epoch 76, Optimized Weights are [1.99926953], and bias is 0.0037740948765889438\n",
            "Epoch 77, Optimized Weights are [1.99932176], and bias is 0.0035042470929126748\n",
            "Epoch 78, Optimized Weights are [1.99937025], and bias is 0.0032536934257696142\n",
            "Epoch 79, Optimized Weights are [1.99941528], and bias is 0.0030210543458270827\n",
            "Epoch 80, Optimized Weights are [1.99945709], and bias is 0.0028050489601004246\n",
            "Epoch 81, Optimized Weights are [1.99949591], and bias is 0.00260448795945331\n",
            "Epoch 82, Optimized Weights are [1.99953195], and bias is 0.0024182670703523693\n",
            "Epoch 83, Optimized Weights are [1.99956541], and bias is 0.002245360974822191\n",
            "Epoch 84, Optimized Weights are [1.99959649], and bias is 0.0020848176651223124\n",
            "Epoch 85, Optimized Weights are [1.99962534], and bias is 0.0019357532020660866\n",
            "Epoch 86, Optimized Weights are [1.99965213], and bias is 0.0017973468481184247\n",
            "Epoch 87, Optimized Weights are [1.999677], and bias is 0.001668836548478064\n",
            "Epoch 88, Optimized Weights are [1.99970009], and bias is 0.001549514735261875\n",
            "Epoch 89, Optimized Weights are [1.99972154], and bias is 0.0014387244316907016\n",
            "Epoch 90, Optimized Weights are [1.99974145], and bias is 0.001335855634824739\n",
            "Epoch 91, Optimized Weights are [1.99975993], and bias is 0.0012403419569347366\n",
            "Epoch 92, Optimized Weights are [1.9997771], and bias is 0.001151657507013908\n",
            "Epoch 93, Optimized Weights are [1.99979304], and bias is 0.0010693139952622822\n",
            "Epoch 94, Optimized Weights are [1.99980783], and bias is 0.0009928580446010907\n",
            "Epoch 95, Optimized Weights are [1.99982157], and bias is 0.0009218686944121915\n",
            "Epoch 96, Optimized Weights are [1.99983433], and bias is 0.0008559550827616993\n",
            "Epoch 97, Optimized Weights are [1.99984618], and bias is 0.0007947542943442066\n",
            "Epoch 98, Optimized Weights are [1.99985717], and bias is 0.000737929362298544\n",
            "Epoch 99, Optimized Weights are [1.99986739], and bias is 0.0006851674128942766\n",
            "Optimized Weights are [1.99986739] and bias is 0.0006851674128942766\n",
            "Input: [1], Predictions: 2.0005525543652376\n",
            "Input: [2], Predictions: 4.00041994131758\n",
            "Input: [3], Predictions: 6.000287328269923\n",
            "Input: [4], Predictions: 8.000154715222267\n"
          ]
        }
      ]
    }
  ]
}